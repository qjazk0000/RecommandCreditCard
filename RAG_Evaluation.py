'''
RAGASë¥¼ ì´ìš©í•œ RAG ì‹œìŠ¤í…œ ì„±ëŠ¥ í‰ê°€
'''
import os
from typing import List, Dict, Optional, Any
from dataclasses import dataclass
from dotenv import load_dotenv

from ragas import evaluate
from ragas.metrics import faithfulness, answer_relevancy
from datasets import Dataset

# RecommendCard.pyì—ì„œ ì¹´ë“œ ì¶”ì²œ ì‹œìŠ¤í…œ import
from RecommendCard import get_recommendation_system


@dataclass  # RAGAS í‰ê°€ ê²°ê³¼(ì ìˆ˜ ë“±) ì €ì¥ ë°ì´í„° í´ë˜ìŠ¤
class EvaluationResult:
    """í‰ê°€ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""
    faithfulness_score: float
    answer_relevancy_score: float
    average_score: float
    interpretation: str
    raw_results: Any


class EnvironmentValidator:  # í™˜ê²½ ë³€ìˆ˜(OPENAI API KEY ë“±) ê²€ì¦ í´ë˜ìŠ¤
    """í™˜ê²½ ë³€ìˆ˜ ê²€ì¦ í´ë˜ìŠ¤"""
    
    @staticmethod
    def validate_openai_key() -> None:
        """OpenAI API í‚¤ ê²€ì¦"""
        if not os.getenv("OPENAI_API_KEY"):
            raise ValueError(
                "âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"
                "1. .env íŒŒì¼ì— OPENAI_API_KEY=your_api_keyë¥¼ ì¶”ê°€í•˜ì„¸ìš”.\n"
                "2. ë˜ëŠ” í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •í•˜ì„¸ìš”."
            )


class DatasetBuilder:  # í‰ê°€ìš© ë°ì´í„°ì…‹ ìƒì„± ë° ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ í´ë˜ìŠ¤
    """í‰ê°€ìš© ë°ì´í„°ì…‹ ìƒì„± í´ë˜ìŠ¤"""
    
    def __init__(self, recommendation_system):
        self.recommendation_system = recommendation_system
    
    def create_single_question_dataset(self, user_question: str) -> Dataset:
        """ë‹¨ì¼ ì§ˆë¬¸ì— ëŒ€í•œ í‰ê°€ìš© ë°ì´í„°ì…‹ ìƒì„±"""
        # ì¹´ë“œ ì¶”ì²œ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ ìƒì„±
        answer = self.recommendation_system.recommend_cards(user_question)
        
        # ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
        context_texts = self._extract_contexts(user_question)
        
        # RAGAS ìš”êµ¬ì‚¬í•­ì— ë§ëŠ” ë°ì´í„°ì…‹ ìƒì„±
        # contextsëŠ” ê° ì§ˆë¬¸ì— ëŒ€í•´ ë¦¬ìŠ¤íŠ¸ í˜•íƒœì—¬ì•¼ í•¨
        return Dataset.from_dict({
            "question": [user_question],
            "answer": [answer],
            "contexts": [context_texts]  # ê° ì§ˆë¬¸ì— ëŒ€í•œ ì»¨í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
        })
    
    def _extract_contexts(self, user_question: str) -> List[str]:
        """ì§ˆë¬¸ì— ëŒ€í•œ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        if not self.recommendation_system.model_manager.retriever:
            raise ValueError("Retrieverê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        docs = self.recommendation_system.model_manager.retriever.invoke(user_question)
        context_texts = []
        
        for doc in docs:
            if hasattr(doc, 'page_content'):
                context_texts.append(doc.page_content)
        
        print(f"ì¶”ì¶œëœ ì»¨í…ìŠ¤íŠ¸ ìˆ˜: {len(context_texts)}")
        if context_texts:
            print(f"ì²« ë²ˆì§¸ ì»¨í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°: {context_texts[0][:200]}...")
        
        return context_texts


class RAGASEvaluator:  # RAGAS í‰ê°€ ì‹¤í–‰ ë° ê²°ê³¼ íŒŒì‹± í´ë˜ìŠ¤
    """RAGAS í‰ê°€ ì‹¤í–‰ í´ë˜ìŠ¤"""
    
    METRICS = [faithfulness, answer_relevancy]
    
    @staticmethod
    def evaluate_dataset(dataset: Dataset) -> EvaluationResult:
        """ë°ì´í„°ì…‹ì— ëŒ€í•œ RAGAS í‰ê°€ ì‹¤í–‰"""
        print("RAGAS í‰ê°€ ì‹¤í–‰ ì¤‘...")
        print(f"ë°ì´í„°ì…‹ êµ¬ì¡°: {dataset}")
        print(f"ë°ì´í„°ì…‹ ì»¬ëŸ¼: {dataset.column_names}")
        print(f"ë°ì´í„°ì…‹ í¬ê¸°: {len(dataset)}")
        
        # ë°ì´í„°ì…‹ êµ¬ì¡° í™•ì¸
        if len(dataset) > 0:
            print(f"ì²« ë²ˆì§¸ ì§ˆë¬¸: {dataset['question'][0]}")
            print(f"ì²« ë²ˆì§¸ ë‹µë³€: {dataset['answer'][0][:200]}...")
            print(f"ì²« ë²ˆì§¸ ì»¨í…ìŠ¤íŠ¸ ìˆ˜: {len(dataset['contexts'][0])}")
        
        # í‰ê°€ ì‹¤í–‰
        results = evaluate(dataset, RAGASEvaluator.METRICS)
        
        print(f"RAGAS ì›ë³¸ ê²°ê³¼: {results}")
        
        # ê²°ê³¼ íŒŒì‹±
        return RAGASEvaluator._parse_results(results)
    
    @staticmethod
    def _parse_results(results: Any) -> EvaluationResult:
        """RAGAS ê²°ê³¼ íŒŒì‹±"""
        try:
            print(f"ê²°ê³¼ íƒ€ì…: {type(results)}")
            print(f"ê²°ê³¼ ì†ì„±ë“¤: {dir(results)}")
            
            faithfulness_score = None
            answer_relevancy_score = None

            # 1. scores
            if hasattr(results, 'scores') and isinstance(results.scores, dict):
                scores = results.scores
                print(f"scores ì†ì„±: {scores}")
                f = scores.get('faithfulness', 0.0)
                a = scores.get('answer_relevancy', 0.0)
                faithfulness_score = float(f[0]) if isinstance(f, list) else float(f)
                answer_relevancy_score = float(a[0]) if isinstance(a, list) else float(a)
                print(f"[scores] faithfulness: {faithfulness_score}, answer_relevancy: {answer_relevancy_score}")

            # 2. _scores_dict
            if (faithfulness_score is None or answer_relevancy_score is None) and hasattr(results, '_scores_dict'):
                scores_dict = results._scores_dict
                print(f"_scores_dict ì†ì„±: {scores_dict}")
                f = scores_dict.get('faithfulness', 0.0)
                a = scores_dict.get('answer_relevancy', 0.0)
                faithfulness_score = float(f[0]) if isinstance(f, list) else float(f)
                answer_relevancy_score = float(a[0]) if isinstance(a, list) else float(a)
                print(f"[_scores_dict] faithfulness: {faithfulness_score}, answer_relevancy: {answer_relevancy_score}")

            # 3. dict
            if (faithfulness_score is None or answer_relevancy_score is None) and isinstance(results, dict):
                f = results.get('faithfulness', 0.0)
                a = results.get('answer_relevancy', 0.0)
                faithfulness_score = float(f[0]) if isinstance(f, list) else float(f)
                answer_relevancy_score = float(a[0]) if isinstance(a, list) else float(a)
                print(f"[dict] faithfulness: {faithfulness_score}, answer_relevancy: {answer_relevancy_score}")

            # 4. ì§ì ‘ ì†ì„±
            if (faithfulness_score is None or answer_relevancy_score is None):
                faithfulness_score = float(getattr(results, 'faithfulness', 0.0))
                answer_relevancy_score = float(getattr(results, 'answer_relevancy', 0.0))
                print(f"[attr] faithfulness: {faithfulness_score}, answer_relevancy: {answer_relevancy_score}")

            # í‰ê·  ì ìˆ˜ ê³„ì‚°
            scores = [faithfulness_score, answer_relevancy_score]
            average_score = sum(scores) / len(scores)

            # ê²°ê³¼ í•´ì„
            interpretation = RAGASEvaluator._interpret_score(average_score)

            return EvaluationResult(
                faithfulness_score=faithfulness_score,
                answer_relevancy_score=answer_relevancy_score,
                average_score=average_score,
                interpretation=interpretation,
                raw_results=results
            )

        except Exception as e:
            print(f"ê²°ê³¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            print("ì›ë³¸ ê²°ê³¼:", results)
            
            # ê¸°ë³¸ê°’ ë°˜í™˜
            return EvaluationResult(
                faithfulness_score=0.0,
                answer_relevancy_score=0.0,
                average_score=0.0,
                interpretation="ê²°ê³¼ ì²˜ë¦¬ ì‹¤íŒ¨",
                raw_results=results
            )
    
    @staticmethod
    def _interpret_score(score: float) -> str:
        """ì ìˆ˜ í•´ì„"""
        if score >= 0.8:
            return "ğŸŸ¢ ìš°ìˆ˜í•œ ì„±ëŠ¥: ë‹µë³€ì´ ë§¤ìš° ì •í™•í•˜ê³  ê´€ë ¨ì„±ì´ ë†’ìŠµë‹ˆë‹¤."
        elif score >= 0.6:
            return "ğŸŸ¡ ì–‘í˜¸í•œ ì„±ëŠ¥: ë‹µë³€ì´ ì ì ˆí•œ ìˆ˜ì¤€ì…ë‹ˆë‹¤."
        else:
            return "ğŸ”´ ê°œì„  í•„ìš”: ë‹µë³€ì˜ í’ˆì§ˆì„ í–¥ìƒì‹œí‚¬ í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤."


class ResultPrinter:  # í‰ê°€ ê²°ê³¼(ì ìˆ˜, í•´ì„ ë“±) ì¶œë ¥ í´ë˜ìŠ¤
    """ê²°ê³¼ ì¶œë ¥ í´ë˜ìŠ¤"""
    
    @staticmethod
    def print_evaluation_results(question: str, result: EvaluationResult, answer: str) -> None:
        """í‰ê°€ ê²°ê³¼ ì¶œë ¥"""
        print(f"\n=== RAGAS í‰ê°€ ê²°ê³¼ ===")
        print(f"faithfulness: {result.faithfulness_score:.3f}")
        print(f"answer_relevancy: {result.answer_relevancy_score:.3f}")
        print(f"\ní‰ê·  ì ìˆ˜: {result.average_score:.3f}")
        
        print(f"\n=== ê²°ê³¼ í•´ì„ ===")
        print(result.interpretation)
        
        print(f"\n=== ìƒì„±ëœ ë‹µë³€ ===")
        print(answer)


class RAGEvaluator:  # ì „ì²´ í‰ê°€ íŒŒì´í”„ë¼ì¸ ê´€ë¦¬ í´ë˜ìŠ¤
    """RAG ì‹œìŠ¤í…œ ì„±ëŠ¥ í‰ê°€ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.recommendation_system = None
        self.dataset_builder = None
    
    def initialize(self) -> None:
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        print("ì¹´ë“œ ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        
        # í™˜ê²½ ë³€ìˆ˜ ê²€ì¦
        load_dotenv()
        EnvironmentValidator.validate_openai_key()
        
        # ì¹´ë“œ ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self.recommendation_system = get_recommendation_system()
        self.dataset_builder = DatasetBuilder(self.recommendation_system)
        
        print("ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def evaluate_single_question(self, user_question: str) -> Optional[EvaluationResult]:
        """ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ë‹¨ì¼ í‰ê°€"""
        print(f"=== ì§ˆë¬¸ í‰ê°€: {user_question} ===")
        
        try:
            if not self.dataset_builder:
                raise ValueError("ë°ì´í„°ì…‹ ë¹Œë”ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            # ë°ì´í„°ì…‹ ìƒì„±
            dataset = self.dataset_builder.create_single_question_dataset(user_question)
            
            # RAGAS í‰ê°€ ì‹¤í–‰
            result = RAGASEvaluator.evaluate_dataset(dataset)
            
            # ë‹µë³€ ì¶”ì¶œ (ë°ì´í„°ì…‹ì—ì„œ)
            answer = dataset["answer"][0]
            
            # ê²°ê³¼ ì¶œë ¥
            ResultPrinter.print_evaluation_results(user_question, result, answer)
            
            return result
            
        except Exception as e:
            print(f"í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            return None


class InteractiveEvaluator:  # CLIì—ì„œ ì‹¤ì‹œê°„ í‰ê°€ ì¸í„°í˜ì´ìŠ¤ ì œê³µ í´ë˜ìŠ¤
    """ëŒ€í™”í˜• í‰ê°€ ì¸í„°í˜ì´ìŠ¤"""
    
    def __init__(self):
        self.evaluator = RAGEvaluator()
    
    def run(self) -> None:
        """ëŒ€í™”í˜• í‰ê°€ ì‹¤í–‰"""
        print("=== RAGAS ì‹¤ì‹œê°„ í‰ê°€ ì‹œìŠ¤í…œ ===")
        print("ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•´ RAGAS ì§€í‘œë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤.")
        print("ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ë˜ëŠ” 'exit'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        print()
        
        try:
            self.evaluator.initialize()
            
            while True:
                user_question = self._get_user_input()
                
                if user_question is None:  # ì¢…ë£Œ ì‹ í˜¸
                    break
                
                if not user_question:  # ë¹ˆ ì…ë ¥
                    print("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                    continue
                
                # í‰ê°€ ì‹¤í–‰
                self.evaluator.evaluate_single_question(user_question)
                print("\n" + "="*50 + "\n")
        
        except Exception as e:
            print(f"ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def _get_user_input(self) -> Optional[str]:
        """ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°"""
        try:
            user_input = input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
            
            if user_input.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
                print("í‰ê°€ ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                return None
            
            return user_input
            
        except KeyboardInterrupt:
            print("\ní‰ê°€ ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return None
        except EOFError:
            print("\ní‰ê°€ ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return None


def main():  # í‰ê°€ CLI ì‹¤í–‰ í•¨ìˆ˜
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    evaluator = InteractiveEvaluator()
    evaluator.run()


if __name__ == "__main__":
    main() 