'''
RAGASë¥¼ ì´ìš©í•œ RAG ì‹œìŠ¤í…œ ì„±ëŠ¥ í‰ê°€
'''
import os
from typing import List, Dict, Optional, Any
from dataclasses import dataclass
from dotenv import load_dotenv

from ragas import evaluate
from ragas.metrics import faithfulness, answer_relevancy
from datasets import Dataset

# RecommendCard.pyì—ì„œ ì¹´ë“œ ì¶”ì²œ ì‹œìŠ¤í…œ import
from RecommendCard import get_recommendation_system


@dataclass
class EvaluationResult:
    """í‰ê°€ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""
    faithfulness_score: float
    answer_relevancy_score: float
    average_score: float
    interpretation: str
    raw_results: Any


class EnvironmentValidator:
    """í™˜ê²½ ë³€ìˆ˜ ê²€ì¦ í´ë˜ìŠ¤"""
    
    @staticmethod
    def validate_openai_key() -> None:
        """OpenAI API í‚¤ ê²€ì¦"""
        if not os.getenv("OPENAI_API_KEY"):
            raise ValueError(
                "âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"
                "1. .env íŒŒì¼ì— OPENAI_API_KEY=your_api_keyë¥¼ ì¶”ê°€í•˜ì„¸ìš”.\n"
                "2. ë˜ëŠ” í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •í•˜ì„¸ìš”."
            )


class DatasetBuilder:
    """í‰ê°€ìš© ë°ì´í„°ì…‹ ìƒì„± í´ë˜ìŠ¤"""
    
    def __init__(self, recommendation_system):
        self.recommendation_system = recommendation_system
    
    def create_single_question_dataset(self, user_question: str) -> Dataset:
        """ë‹¨ì¼ ì§ˆë¬¸ì— ëŒ€í•œ í‰ê°€ìš© ë°ì´í„°ì…‹ ìƒì„±"""
        # ì¹´ë“œ ì¶”ì²œ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ ìƒì„±
        answer = self.recommendation_system.recommend_cards(user_question)
        
        # ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
        context_texts = self._extract_contexts(user_question)
        
        # ë°ì´í„°ì…‹ ìƒì„±
        return Dataset.from_dict({
            "question": [user_question],
            "answer": [answer],
            "contexts": [context_texts]
        })
    
    def _extract_contexts(self, user_question: str) -> List[str]:
        """ì§ˆë¬¸ì— ëŒ€í•œ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        if not self.recommendation_system.retriever:
            raise ValueError("Retrieverê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        docs = self.recommendation_system.retriever.invoke(user_question)
        context_texts = []
        
        for doc in docs:
            if hasattr(doc, 'page_content'):
                context_texts.append(doc.page_content)
        
        return context_texts


class RAGASEvaluator:
    """RAGAS í‰ê°€ ì‹¤í–‰ í´ë˜ìŠ¤"""
    
    METRICS = [faithfulness, answer_relevancy]
    
    @staticmethod
    def evaluate_dataset(dataset: Dataset) -> EvaluationResult:
        """ë°ì´í„°ì…‹ì— ëŒ€í•œ RAGAS í‰ê°€ ì‹¤í–‰"""
        print("RAGAS í‰ê°€ ì‹¤í–‰ ì¤‘...")
        
        # í‰ê°€ ì‹¤í–‰
        results = evaluate(dataset, RAGASEvaluator.METRICS)
        
        # ê²°ê³¼ íŒŒì‹±
        return RAGASEvaluator._parse_results(results)
    
    @staticmethod
    def _parse_results(results: Any) -> EvaluationResult:
        """RAGAS ê²°ê³¼ íŒŒì‹±"""
        try:
            # ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            results_dict = {}
            for metric in RAGASEvaluator.METRICS:
                metric_name = metric.__name__ if hasattr(metric, '__name__') else str(metric)
                
                if hasattr(results, metric_name):
                    results_dict[metric_name] = getattr(results, metric_name)
                elif isinstance(results, dict) and metric_name in results:
                    results_dict[metric_name] = results[metric_name]
            
            # ì ìˆ˜ ì¶”ì¶œ
            faithfulness_score = results_dict.get('faithfulness', 0.0)
            answer_relevancy_score = results_dict.get('answer_relevancy', 0.0)
            
            # í‰ê·  ì ìˆ˜ ê³„ì‚°
            scores = [faithfulness_score, answer_relevancy_score]
            average_score = sum(scores) / len(scores)
            
            # ê²°ê³¼ í•´ì„
            interpretation = RAGASEvaluator._interpret_score(average_score)
            
            return EvaluationResult(
                faithfulness_score=faithfulness_score,
                answer_relevancy_score=answer_relevancy_score,
                average_score=average_score,
                interpretation=interpretation,
                raw_results=results
            )
            
        except Exception as e:
            print(f"ê²°ê³¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            print("ì›ë³¸ ê²°ê³¼:", results)
            
            # ê¸°ë³¸ê°’ ë°˜í™˜
            return EvaluationResult(
                faithfulness_score=0.0,
                answer_relevancy_score=0.0,
                average_score=0.0,
                interpretation="ê²°ê³¼ ì²˜ë¦¬ ì‹¤íŒ¨",
                raw_results=results
            )
    
    @staticmethod
    def _interpret_score(score: float) -> str:
        """ì ìˆ˜ í•´ì„"""
        if score >= 0.8:
            return "ğŸŸ¢ ìš°ìˆ˜í•œ ì„±ëŠ¥: ë‹µë³€ì´ ë§¤ìš° ì •í™•í•˜ê³  ê´€ë ¨ì„±ì´ ë†’ìŠµë‹ˆë‹¤."
        elif score >= 0.6:
            return "ğŸŸ¡ ì–‘í˜¸í•œ ì„±ëŠ¥: ë‹µë³€ì´ ì ì ˆí•œ ìˆ˜ì¤€ì…ë‹ˆë‹¤."
        else:
            return "ğŸ”´ ê°œì„  í•„ìš”: ë‹µë³€ì˜ í’ˆì§ˆì„ í–¥ìƒì‹œí‚¬ í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤."


class ResultPrinter:
    """ê²°ê³¼ ì¶œë ¥ í´ë˜ìŠ¤"""
    
    @staticmethod
    def print_evaluation_results(question: str, result: EvaluationResult, answer: str) -> None:
        """í‰ê°€ ê²°ê³¼ ì¶œë ¥"""
        print(f"\n=== RAGAS í‰ê°€ ê²°ê³¼ ===")
        print(f"faithfulness: {result.faithfulness_score:.3f}")
        print(f"answer_relevancy: {result.answer_relevancy_score:.3f}")
        print(f"\ní‰ê·  ì ìˆ˜: {result.average_score:.3f}")
        
        print(f"\n=== ê²°ê³¼ í•´ì„ ===")
        print(result.interpretation)
        
        print(f"\n=== ìƒì„±ëœ ë‹µë³€ ===")
        print(answer)


class RAGEvaluator:
    """RAG ì‹œìŠ¤í…œ ì„±ëŠ¥ í‰ê°€ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.recommendation_system = None
        self.dataset_builder = None
    
    def initialize(self) -> None:
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        print("ì¹´ë“œ ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        
        # í™˜ê²½ ë³€ìˆ˜ ê²€ì¦
        load_dotenv()
        EnvironmentValidator.validate_openai_key()
        
        # ì¹´ë“œ ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self.recommendation_system = get_recommendation_system()
        self.dataset_builder = DatasetBuilder(self.recommendation_system)
        
        print("ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def evaluate_single_question(self, user_question: str) -> Optional[EvaluationResult]:
        """ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ë‹¨ì¼ í‰ê°€"""
        print(f"=== ì§ˆë¬¸ í‰ê°€: {user_question} ===")
        
        try:
            if not self.dataset_builder:
                raise ValueError("ë°ì´í„°ì…‹ ë¹Œë”ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            # ë°ì´í„°ì…‹ ìƒì„±
            dataset = self.dataset_builder.create_single_question_dataset(user_question)
            
            # RAGAS í‰ê°€ ì‹¤í–‰
            result = RAGASEvaluator.evaluate_dataset(dataset)
            
            # ë‹µë³€ ì¶”ì¶œ (ë°ì´í„°ì…‹ì—ì„œ)
            answer = dataset["answer"][0]
            
            # ê²°ê³¼ ì¶œë ¥
            ResultPrinter.print_evaluation_results(user_question, result, answer)
            
            return result
            
        except Exception as e:
            print(f"í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None


class InteractiveEvaluator:
    """ëŒ€í™”í˜• í‰ê°€ ì¸í„°í˜ì´ìŠ¤"""
    
    def __init__(self):
        self.evaluator = RAGEvaluator()
    
    def run(self) -> None:
        """ëŒ€í™”í˜• í‰ê°€ ì‹¤í–‰"""
        print("=== RAGAS ì‹¤ì‹œê°„ í‰ê°€ ì‹œìŠ¤í…œ ===")
        print("ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•´ RAGAS ì§€í‘œë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤.")
        print("ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ë˜ëŠ” 'exit'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        print()
        
        try:
            self.evaluator.initialize()
            
            while True:
                user_question = self._get_user_input()
                
                if user_question is None:  # ì¢…ë£Œ ì‹ í˜¸
                    break
                
                if not user_question:  # ë¹ˆ ì…ë ¥
                    print("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                    continue
                
                # í‰ê°€ ì‹¤í–‰
                self.evaluator.evaluate_single_question(user_question)
                print("\n" + "="*50 + "\n")
        
        except Exception as e:
            print(f"ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def _get_user_input(self) -> Optional[str]:
        """ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°"""
        try:
            user_input = input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
            
            if user_input.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
                print("í‰ê°€ ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                return None
            
            return user_input
            
        except KeyboardInterrupt:
            print("\ní‰ê°€ ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return None
        except EOFError:
            print("\ní‰ê°€ ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return None


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    evaluator = InteractiveEvaluator()
    evaluator.run()


if __name__ == "__main__":
    main() 